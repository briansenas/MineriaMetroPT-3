{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T18:42:43.137084Z",
     "start_time": "2025-01-22T18:42:43.118949Z"
    }
   },
   "source": [
    "import polars as pl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n"
   ],
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:42:43.355717Z",
     "start_time": "2025-01-22T18:42:43.294741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pl.read_csv(TRAIN_PATH)\n",
    "test = pl.read_csv(TEST_PATH)\n",
    "skew_columns = [c for c in train.columns if \"skew\" in c]\n",
    "train = train.select(pl.exclude(skew_columns))\n",
    "test = test.select(pl.exclude(skew_columns))\n"
   ],
   "id": "169acff0d603a127",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:42:43.510837Z",
     "start_time": "2025-01-22T18:42:43.490767Z"
    }
   },
   "cell_type": "code",
   "source": "test.group_by(\"is_anomaly\").len()",
   "id": "e5d3d3479087b6e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────────┬─────┐\n",
       "│ is_anomaly ┆ len │\n",
       "│ ---        ┆ --- │\n",
       "│ bool       ┆ u32 │\n",
       "╞════════════╪═════╡\n",
       "│ false      ┆ 882 │\n",
       "│ true       ┆ 30  │\n",
       "└────────────┴─────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>is_anomaly</th><th>len</th></tr><tr><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>false</td><td>882</td></tr><tr><td>true</td><td>30</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# X, y = load_iris(return_X_y=True)\n",
    "# clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "# clf.predict(X[:2, :])\n",
    "def manual_fold_training(\n",
    "        clf_model : LogisticRegression,\n",
    "        data : pl.DataFrame,\n",
    "        fold_number : int = 0,\n",
    "        *,\n",
    "        target_column : str = \"is_anomaly\"\n",
    "):\n",
    "    scores = {\"fold\":fold_number}\n",
    "    \n",
    "    fold_train = data.filter(pl.col(\"fold\") != fold_number).drop(\"fold\")\n",
    "    fold_test = data.filter(pl.col(\"fold\") == fold_number).drop(\"fold\")\n",
    "    X_train = (fold_train.select(pl.exclude(target_column))\n",
    "               .select(pl.col(pl.Float64)).with_columns(\n",
    "        pl.all().fill_nan(0)\n",
    "    ).to_numpy())\n",
    "    y_train =  fold_train.select(target_column).to_series().to_list()\n",
    "    clf_model.fit(X_train,y_train)\n",
    "    X_test = fold_test.select(pl.exclude(target_column)).to_numpy()\n",
    "    y_test =  fold_test.select(pl.col(target_column)).to_series().to_numpy()\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    scores[\"f1_score\"] = f1_score(y_test,y_pred)\n",
    "    scores[\"recall\"] = recall_score(y_test,y_pred)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "    \n",
    "logistic_regressor = LogisticRegression(solver='liblinear',C=100.0,penalty=\"l2\",max_iter=1000)\n",
    "\n",
    "fold_scores = []\n",
    "for fold in train[\"fold\"].unique().to_list():\n",
    "    fold_scores.append(manual_fold_training(clf_model=logistic_regressor,\n",
    "                         data=train,\n",
    "                         fold_number=fold))\n",
    "    \n",
    "    \n",
    "df_scores = pl.DataFrame(fold_scores)\n",
    "# mean_row = df_scores.select(pl.all().mean().cast(pl.Float64))\n",
    "# df_with_mean = df_scores.with_columns(pl.col(\"fold\").cast(pl.Utf8)).vstack(mean_row)\n",
    "# df_with_mean\n",
    "mean_row"
   ],
   "id": "618eca8ddae6c34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed = 140421\n",
    "np.random.seed(seed)\n",
    "\n",
    "target_column = 'is_anomaly'\n",
    "fold_column = 'fold'\n",
    "\n",
    "X_train = train.select(pl.exclude(target_column)).to_pandas()\n",
    "y_train =  train.select(target_column).to_series().to_numpy()\n",
    "\n",
    "def get_cv_iterable(\n",
    "  folds: list,\n",
    "  fold_column: str,\n",
    "  train: pd.DataFrame,\n",
    "):\n",
    "    print(train.columns)\n",
    "    for fold in folds:\n",
    "        test_indexes = train[train[fold_column] == fold].index\n",
    "        train_indexes = train[train[fold_column] != fold].index\n",
    "        yield (train_indexes, test_indexes)\n",
    "\n",
    "# X_test = test_data[feature_columns]\n",
    "# y_test = test_data[target_column]\n",
    "\n",
    "# Set up cross-validation using the 'folds' column\n",
    "folds = train[\"fold\"].unique().to_list()\n",
    " \n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}\n",
    "cv = GridSearchCV(\n",
    "  estimator = LogisticRegression(solver='liblinear'), \n",
    "  param_grid=grid,\n",
    "  cv = get_cv_iterable(folds, fold_column, X_train),\n",
    "  scoring=[\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\", \n",
    "    \"accuracy\"\n",
    "  ],\n",
    "  refit=\"f1\",\n",
    ")\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "with pd.option_context(\"display.max_columns\", 33):\n",
    "  display(pd.DataFrame(cv.cv_results_))\n"
   ],
   "id": "4bf5f1f0d7120cd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pl.DataFrame(cv.cv_results_).select(\"params\",\"mean_test_f1\")",
   "id": "ac51b39450238512",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:48:19.417565Z",
     "start_time": "2025-01-22T17:48:17.808282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "grid = {\"estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"n_estimators\": [1, 2]\n",
    "             }\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "cv2 = GridSearchCV(\n",
    "    estimator = AdaBoostClassifier(estimator = DTC),\n",
    "    param_grid=grid,\n",
    "    cv = get_cv_iterable(folds, fold_column, X_train),\n",
    "    scoring=[\n",
    "        \"f1\",\n",
    "        \"recall\",\n",
    "        \"precision\",\n",
    "        \"accuracy\"\n",
    "    ],\n",
    "    refit=\"f1\",\n",
    ")\n",
    "\n",
    "\n",
    "cv2.fit(X_train, y_train)\n",
    "with pd.option_context(\"display.max_columns\", 33):\n",
    "    display(pd.DataFrame(cv2.cv_results_))\n",
    "\n"
   ],
   "id": "abdaadedc417fec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TP2_mean', 'TP2_max', 'TP2_min', 'TP2_median', 'TP2_var', 'TP3_mean',\n",
      "       'TP3_max', 'TP3_min', 'TP3_median', 'TP3_var', 'H1_mean', 'H1_max',\n",
      "       'H1_min', 'H1_median', 'H1_var', 'DV_pressure_mean', 'DV_pressure_max',\n",
      "       'DV_pressure_min', 'DV_pressure_median', 'DV_pressure_var',\n",
      "       'Reservoirs_mean', 'Reservoirs_max', 'Reservoirs_min',\n",
      "       'Reservoirs_median', 'Reservoirs_var', 'Oil_temperature_mean',\n",
      "       'Oil_temperature_max', 'Oil_temperature_min', 'Oil_temperature_median',\n",
      "       'Oil_temperature_var', 'Motor_current_mean', 'Motor_current_max',\n",
      "       'Motor_current_min', 'Motor_current_median', 'Motor_current_var',\n",
      "       'COMP_mean', 'COMP_max', 'COMP_min', 'COMP_median', 'COMP_var',\n",
      "       'DV_eletric_mean', 'DV_eletric_max', 'DV_eletric_min',\n",
      "       'DV_eletric_median', 'DV_eletric_var', 'Towers_mean', 'Towers_max',\n",
      "       'Towers_min', 'Towers_median', 'Towers_var', 'MPG_mean', 'MPG_max',\n",
      "       'MPG_min', 'MPG_median', 'MPG_var', 'LPS_mean', 'LPS_max', 'LPS_min',\n",
      "       'LPS_median', 'LPS_var', 'Pressure_switch_mean', 'Pressure_switch_max',\n",
      "       'Pressure_switch_min', 'Pressure_switch_median', 'Pressure_switch_var',\n",
      "       'Oil_level_mean', 'Oil_level_max', 'Oil_level_min', 'Oil_level_median',\n",
      "       'Oil_level_var', 'Caudal_impulses_mean', 'Caudal_impulses_max',\n",
      "       'Caudal_impulses_min', 'Caudal_impulses_median', 'Caudal_impulses_var',\n",
      "       'Motor_State_mean', 'Motor_State_max', 'Motor_State_min',\n",
      "       'Motor_State_median', 'Motor_State_var', 'fold'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.096525      0.021398         0.008470        0.000884   \n",
       "1       0.093657      0.020686         0.007682        0.000424   \n",
       "2       0.012429      0.001025         0.007755        0.000426   \n",
       "3       0.011020      0.001593         0.007252        0.000432   \n",
       "4       0.040762      0.007445         0.007510        0.000520   \n",
       "5       0.041161      0.007161         0.007915        0.000146   \n",
       "6       0.009745      0.000833         0.007667        0.000407   \n",
       "7       0.009782      0.001129         0.007779        0.000873   \n",
       "\n",
       "  param_estimator__criterion param_estimator__splitter param_n_estimators  \\\n",
       "0                       gini                      best                  1   \n",
       "1                       gini                      best                  2   \n",
       "2                       gini                    random                  1   \n",
       "3                       gini                    random                  2   \n",
       "4                    entropy                      best                  1   \n",
       "5                    entropy                      best                  2   \n",
       "6                    entropy                    random                  1   \n",
       "7                    entropy                    random                  2   \n",
       "\n",
       "                                              params  split0_test_f1  \\\n",
       "0  {'estimator__criterion': 'gini', 'estimator__s...        0.836364   \n",
       "1  {'estimator__criterion': 'gini', 'estimator__s...        0.800000   \n",
       "2  {'estimator__criterion': 'gini', 'estimator__s...        0.814815   \n",
       "3  {'estimator__criterion': 'gini', 'estimator__s...        0.814815   \n",
       "4  {'estimator__criterion': 'entropy', 'estimator...        0.807692   \n",
       "5  {'estimator__criterion': 'entropy', 'estimator...        0.814815   \n",
       "6  {'estimator__criterion': 'entropy', 'estimator...        0.836364   \n",
       "7  {'estimator__criterion': 'entropy', 'estimator...        0.750000   \n",
       "\n",
       "   split1_test_f1  split2_test_f1  split3_test_f1  mean_test_f1  std_test_f1  \\\n",
       "0        0.861538        0.729560        0.909091      0.834138     0.065784   \n",
       "1        0.861538        0.721519        0.928571      0.827907     0.076423   \n",
       "2        0.811594        0.899329        0.912281      0.859505     0.046540   \n",
       "3        0.861538        0.887324        0.947368      0.877761     0.047859   \n",
       "4        0.675325        0.873239        0.877193      0.808362     0.081618   \n",
       "5        0.716418        0.849315        0.877193      0.814435     0.060751   \n",
       "6        0.800000        0.835443        0.965517      0.859331     0.063035   \n",
       "7        0.710526        0.853659        0.947368      0.815388     0.092405   \n",
       "\n",
       "   rank_test_f1  split0_test_recall  ...  std_test_recall  rank_test_recall  \\\n",
       "0             4            0.766667  ...         0.061661                 5   \n",
       "1             5            0.733333  ...         0.075548                 6   \n",
       "2             2            0.733333  ...         0.081090                 3   \n",
       "3             1            0.733333  ...         0.076234                 4   \n",
       "4             8            0.700000  ...         0.067743                 7   \n",
       "5             7            0.733333  ...         0.047690                 8   \n",
       "6             3            0.766667  ...         0.070094                 1   \n",
       "7             6            0.700000  ...         0.101408                 2   \n",
       "\n",
       "   split0_test_precision  split1_test_precision  split2_test_precision  \\\n",
       "0               0.920000               0.800000               0.666667   \n",
       "1               0.880000               0.800000               0.662791   \n",
       "2               0.916667               0.717949               0.870130   \n",
       "3               0.916667               0.800000               0.900000   \n",
       "4               0.954545               0.553191               0.885714   \n",
       "5               0.916667               0.648649               0.837838   \n",
       "6               0.920000               0.700000               0.767442   \n",
       "7               0.807692               0.586957               0.760870   \n",
       "\n",
       "   split3_test_precision  mean_test_precision  std_test_precision  \\\n",
       "0               1.000000             0.846667            0.125963   \n",
       "1               1.000000             0.835698            0.122606   \n",
       "2               0.962963             0.866927            0.092062   \n",
       "3               1.000000             0.904167            0.071078   \n",
       "4               0.925926             0.829844            0.161586   \n",
       "5               0.925926             0.832270            0.111402   \n",
       "6               1.000000             0.846860            0.119034   \n",
       "7               1.000000             0.788880            0.147040   \n",
       "\n",
       "   rank_test_precision  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0                    4              0.986175              0.992941   \n",
       "1                    5              0.983103              0.992941   \n",
       "2                    2              0.984639              0.989804   \n",
       "3                    1              0.984639              0.992941   \n",
       "4                    7              0.984639              0.980392   \n",
       "5                    6              0.984639              0.985098   \n",
       "6                    3              0.986175              0.989020   \n",
       "7                    8              0.978495              0.982745   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  mean_test_accuracy  \\\n",
       "0              0.982745              0.991667            0.988382   \n",
       "1              0.982343              0.993333            0.987930   \n",
       "2              0.993981              0.991667            0.990023   \n",
       "3              0.993579              0.995000            0.991540   \n",
       "4              0.992777              0.988333            0.986535   \n",
       "5              0.991172              0.988333            0.987311   \n",
       "6              0.989567              0.996667            0.990357   \n",
       "7              0.990369              0.995000            0.986652   \n",
       "\n",
       "   std_test_accuracy  rank_test_accuracy  \n",
       "0           0.004130                   4  \n",
       "1           0.005216                   5  \n",
       "2           0.003442                   3  \n",
       "3           0.004053                   1  \n",
       "4           0.004570                   8  \n",
       "5           0.002645                   6  \n",
       "6           0.003864                   2  \n",
       "7           0.006429                   7  \n",
       "\n",
       "[8 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimator__criterion</th>\n",
       "      <th>param_estimator__splitter</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096525</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>{'estimator__criterion': 'gini', 'estimator__s...</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.729560</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.834138</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>4</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061661</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.125963</td>\n",
       "      <td>4</td>\n",
       "      <td>0.986175</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.982745</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.988382</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093657</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>{'estimator__criterion': 'gini', 'estimator__s...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.076423</td>\n",
       "      <td>5</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075548</td>\n",
       "      <td>6</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835698</td>\n",
       "      <td>0.122606</td>\n",
       "      <td>5</td>\n",
       "      <td>0.983103</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.982343</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012429</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>{'estimator__criterion': 'gini', 'estimator__s...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.859505</td>\n",
       "      <td>0.046540</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081090</td>\n",
       "      <td>3</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.866927</td>\n",
       "      <td>0.092062</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984639</td>\n",
       "      <td>0.989804</td>\n",
       "      <td>0.993981</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.990023</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>{'estimator__criterion': 'gini', 'estimator__s...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.877761</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984639</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.993579</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.991540</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040762</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>{'estimator__criterion': 'entropy', 'estimator...</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.808362</td>\n",
       "      <td>0.081618</td>\n",
       "      <td>8</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067743</td>\n",
       "      <td>7</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.829844</td>\n",
       "      <td>0.161586</td>\n",
       "      <td>7</td>\n",
       "      <td>0.984639</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.986535</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041161</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>{'estimator__criterion': 'entropy', 'estimator...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.814435</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>7</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047690</td>\n",
       "      <td>8</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.832270</td>\n",
       "      <td>0.111402</td>\n",
       "      <td>6</td>\n",
       "      <td>0.984639</td>\n",
       "      <td>0.985098</td>\n",
       "      <td>0.991172</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.987311</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>{'estimator__criterion': 'entropy', 'estimator...</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.859331</td>\n",
       "      <td>0.063035</td>\n",
       "      <td>3</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846860</td>\n",
       "      <td>0.119034</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986175</td>\n",
       "      <td>0.989020</td>\n",
       "      <td>0.989567</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.990357</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>{'estimator__criterion': 'entropy', 'estimator...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.815388</td>\n",
       "      <td>0.092405</td>\n",
       "      <td>6</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101408</td>\n",
       "      <td>2</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788880</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>8</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.982745</td>\n",
       "      <td>0.990369</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.986652</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:48:36.334053Z",
     "start_time": "2025-01-22T17:48:36.317247Z"
    }
   },
   "cell_type": "code",
   "source": "pl.DataFrame(cv2.cv_results_).select(\"params\",\"mean_test_f1\")",
   "id": "a92957cc1a27a154",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (8, 2)\n",
       "┌────────────────────────┬──────────────┐\n",
       "│ params                 ┆ mean_test_f1 │\n",
       "│ ---                    ┆ ---          │\n",
       "│ struct[3]              ┆ f64          │\n",
       "╞════════════════════════╪══════════════╡\n",
       "│ {\"gini\",\"best\",1}      ┆ 0.834138     │\n",
       "│ {\"gini\",\"best\",2}      ┆ 0.827907     │\n",
       "│ {\"gini\",\"random\",1}    ┆ 0.859505     │\n",
       "│ {\"gini\",\"random\",2}    ┆ 0.877761     │\n",
       "│ {\"entropy\",\"best\",1}   ┆ 0.808362     │\n",
       "│ {\"entropy\",\"best\",2}   ┆ 0.814435     │\n",
       "│ {\"entropy\",\"random\",1} ┆ 0.859331     │\n",
       "│ {\"entropy\",\"random\",2} ┆ 0.815388     │\n",
       "└────────────────────────┴──────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>params</th><th>mean_test_f1</th></tr><tr><td>struct[3]</td><td>f64</td></tr></thead><tbody><tr><td>{&quot;gini&quot;,&quot;best&quot;,1}</td><td>0.834138</td></tr><tr><td>{&quot;gini&quot;,&quot;best&quot;,2}</td><td>0.827907</td></tr><tr><td>{&quot;gini&quot;,&quot;random&quot;,1}</td><td>0.859505</td></tr><tr><td>{&quot;gini&quot;,&quot;random&quot;,2}</td><td>0.877761</td></tr><tr><td>{&quot;entropy&quot;,&quot;best&quot;,1}</td><td>0.808362</td></tr><tr><td>{&quot;entropy&quot;,&quot;best&quot;,2}</td><td>0.814435</td></tr><tr><td>{&quot;entropy&quot;,&quot;random&quot;,1}</td><td>0.859331</td></tr><tr><td>{&quot;entropy&quot;,&quot;random&quot;,2}</td><td>0.815388</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:46:04.375129Z",
     "start_time": "2025-01-22T18:46:04.352129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = logistic_regressor.predict(test.select([a for a in X_train.columns if \"fold\" != a]))\n",
    "f1_score(test.select(\"is_anomaly\").to_series().to_list(),predictions)"
   ],
   "id": "1810e552ea97482b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:56:38.789189Z",
     "start_time": "2025-01-22T18:56:38.766120Z"
    }
   },
   "cell_type": "code",
   "source": "clfAda = AdaBoostClassifier(DecisionTreeClassifier(random_state = seed,criterion=\"gini\",splitter=\"random\"),n_estimators=2).fit(X_train[[a for a in X_train.columns if \"fold\" != a]],y_train)\n",
   "id": "bc3ddca81625e82d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvaro.santana\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:56:40.963461Z",
     "start_time": "2025-01-22T18:56:40.942709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = clfAda.predict(test.select([a for a in X_train.columns if \"fold\" != a]))\n",
    "f1_score(test.select(\"is_anomaly\").to_series().to_list(),predictions)"
   ],
   "id": "d3c9f6123514c71f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275862068965517"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 207
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
